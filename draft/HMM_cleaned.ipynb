{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 4, Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task is to learn about the how to implement the Hidden Markov Model, especially the Viterbi algorithm.\n",
    "Then use the model to do smoothing and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coronavirus is spreading in Munich and threatening our health. In this exercise, we would like to model the spread of the virus using an HMM model. For this purpose, we set 7 states of pandemic severity (1 for least severe, 7 for most severe). Then, we collect the corona data from April 2020 to December 2021 (21 months in total) and compute the number of new cases and deaths for each month as our observation. Based on this, our task is to find the most likely severity sequence using the Viterbi algorithm, do smoothing, and make a prediction about the severity of future pandemics.\n",
    "\n",
    "Your tasks is to complete the missing code. Make sure that all the functions follow the provided interfaces of the functions, i.e. the output of the function exactly matches the description in the docstring.\n",
    "Adding or modifying code outside of the following comment blocks is not required:\n",
    "\n",
    "```\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    ".....\n",
    "##########################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Outcomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* implement prior matrix, transition model, sensor model\n",
    "* implement viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing and grading, we want to state that you are not allowed to import \n",
    "any other libraries and should not change the structure of the provided functions \n",
    "(i.a. the arguments and the name of the functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca.colormap as cmap\n",
    "import folium\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corona data visualization (Nothing to implement here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start to model the corona situation, we would like to visualize the data first to have a basic understanding of it. Feel free to change some parameters to achieve different visualization settings. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corona data\n",
    "corona_df = pd.read_csv('coronadata_Munich.csv')\n",
    "munich_map_df = gpd.read_file('map/vg2500_krs.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what munich_map_df looks like\n",
    "munich_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need the GEN and geometry columns\n",
    "munich_map_df = munich_map_df[['GEN', 'geometry']]\n",
    "\n",
    "# Only keep Munich and LK Munich\n",
    "munich_map_df = munich_map_df.loc[[224, 239]]\n",
    "munich_map_df['GEN'] = ['Munich','LK Munich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what corona_df looks like\n",
    "corona_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10122\\AppData\\Local\\Temp/ipykernel_7336/1281155843.py:5: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  joined_df['date_sec'] = pd.to_datetime(joined_df['ObservationDate']).astype(np.int64) / 10**9\n"
     ]
    }
   ],
   "source": [
    "# Both dataframes have the column \"GEN\", we merge them using this column\n",
    "joined_df = corona_df.merge(munich_map_df, on='GEN')\n",
    "\n",
    "# The ObservationDate is given in date and time, we convert it to unix time in nanoseconds\n",
    "joined_df['date_sec'] = pd.to_datetime(joined_df['ObservationDate']).astype(np.int64) / 10**9\n",
    "joined_df['date_sec'] = joined_df['date_sec'].astype(int).astype(str)\n",
    "\n",
    "# Delete the ObservationDate column as we do not need it anymore\n",
    "joined_df = joined_df.drop('ObservationDate', axis = 1)\n",
    "\n",
    "# Check the final dataframe before we do the visualization\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we visualize the daily confirmed case\n",
    "# Add the color to each row\n",
    "max_colour = max(joined_df['Confirmed'])\n",
    "min_colour = min(joined_df['Confirmed'])\n",
    "colour_map = cmap.linear.YlOrRd_09.scale(min_colour, max_colour)\n",
    "joined_df['colour'] = joined_df['Confirmed'].map(colour_map)\n",
    "\n",
    "# uncomment the following code to visualize daily death cases\n",
    "#max_colour = max(joined_df['Deaths'])\n",
    "#min_colour = min(joined_df['Deaths'])\n",
    "#colour_map = cmap.linear.YlOrRd_09.scale(min_colour, max_colour)\n",
    "#joined_df['colour'] = joined_df['Deaths'].map(colour_map)\n",
    "\n",
    "# create an inner dictionary for the visualization\n",
    "geo_list = joined_df['GEN'].unique().tolist()\n",
    "geo_idx = range(len(geo_list))\n",
    "\n",
    "style_dict = {}\n",
    "for i in geo_idx:\n",
    "    geo = geo_list[i]\n",
    "    result = joined_df[joined_df['GEN'] == geo]\n",
    "    inner_dict = {}\n",
    "    for _, r in result.iterrows():\n",
    "        inner_dict[r['date_sec']] = {'color': r['colour'], 'opacity': 0.7}\n",
    "    style_dict[str(i)] = inner_dict\n",
    "\n",
    "# create a geo_gdf for the visualization\n",
    "geo_df = joined_df[['geometry']]\n",
    "geo_gdf = gpd.GeoDataFrame(geo_df)\n",
    "geo_gdf = geo_gdf.drop_duplicates().reset_index()\n",
    "\n",
    "#You might need to change the value of min_zoom depending on your platform\n",
    "slider_map = folium.Map(location=[48.08,11.61], min_zoom=2, max_bounds=True)\n",
    "\n",
    "_ = TimeSliderChoropleth(data=geo_gdf.to_json(),styledict=style_dict).add_to(slider_map)\n",
    "_ = colour_map.add_to(slider_map)\n",
    "colour_map.caption = \"confirmed cases in the past 7 days per 100,000 people\"\n",
    "\n",
    "## uncomment for the death cases\n",
    "#colour_map.caption = \"death cases in the past 7 days per 5,000,000 people\"\n",
    "\n",
    "## uncomment the following code to save the figure\n",
    "#slider_map.save(outfile='daily_confirmed_case.html')\n",
    "#slider_map.save(outfile='daily_death_case.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final visualization, drag the bar to see the statistics on different days\n",
    "slider_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the HMM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our HMM model, there are two observations: confirmed cases per 100,000 people and death cases per 5,000,000 people. Unlike the umbrella case in our textbook, our data is continuous, which means we need a continuous HMM model. But don't worry! The transition from a discrete HMM model to a continuous one is easy. In this task, you are only supposed to implement a discrete model.\n",
    "\n",
    "Let's define a class named HMM that is able to execute filtering, smoothing, prediction and the most likely path estimation based on discrete observation data. You will implement the aforementioned functions step by step within the **HMM** class. Vectorized operation given in the textbook will be very useful for during implementation.\n",
    "\n",
    "**Note: During implementation, we refer the state with their associated indices.** For example, as defined in the textbook, the ij-th entry of transition matrix denotes the transformation probability from state j to state i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(state_dict):\n",
    "    state_array = [state_dict[t] for t in sorted(state_dict.keys())]        \n",
    "    return np.array(state_array) \n",
    "\n",
    "class HMM():\n",
    "    def __init__(self, \n",
    "                 observation_mu,\n",
    "                 observation_sigma,\n",
    "                 transition_matrix, \n",
    "                 initial_probability):\n",
    "        assert len(transition_matrix) == len(observation_mu) == len(observation_sigma)\n",
    "        self.trans_mat = transition_matrix\n",
    "        self.obs_mat = [multivariate_normal(observation_mu[i], observation_sigma[i]) \n",
    "                        for i in range(len(observation_mu))]\n",
    "        self.init_prob = initial_probability\n",
    "        self.N_state = len(self.trans_mat)        \n",
    "        \n",
    "    def compute_observation_matrix(self, observation):\n",
    "        \"\"\" Compute the observation matrix for vectorized operation.\n",
    "       \n",
    "        Args:\n",
    "            observation: observation in some timestamp\n",
    "\n",
    "        Return: \n",
    "            O_matrix: observation matrix\n",
    "\n",
    "        \"\"\"\n",
    "        prob_density = [self.obs_mat[i].pdf(observation) for i in range(self.N_state)]\n",
    "        O_matrix = np.diag(prob_density)\n",
    "        return O_matrix\n",
    "\n",
    "\n",
    "    def forward_onestep(self, f, observation):\n",
    "        \"\"\" Compute one forward step for filtering.\n",
    "            N stands for number of hidden states.\n",
    "            Hint: Use the O_matrix we provided for one step forward oepration.\n",
    "\n",
    "        Args:\n",
    "            f: numpy array with shape [N, ], vector of f_{1:t} depicting probability of state given previous observation sequence\n",
    "            observation: observed state in timestamp t+1\n",
    "            \n",
    "\n",
    "        Return: \n",
    "            f_onestep: numpy array with shape [N, ], updated vector of f_{1:t+1}\n",
    "\n",
    "        \"\"\"\n",
    "        # Acquire the row vector and transform it to diagonal matrix\n",
    "        O_matrix = self.compute_observation_matrix(observation)\n",
    "        f_onestep = None\n",
    "        #######################################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #######################################\n",
    "        return f_onestep\n",
    "        \n",
    "        \n",
    "    def backward_onestep(self, b, observation):\n",
    "        \"\"\" Compute one backward step for smoothing \n",
    "            N stands for number of hidden states. \n",
    "            Hint: Use the O_matrix we provided for one step backward.\n",
    "\n",
    "        Args:\n",
    "            b: numpy array with shape [N, ], vector of b_{k+2:T} depicting probability of observation sequence given state\n",
    "            observation: observed state in timestamp k+1\n",
    "            \n",
    "        Return: \n",
    "            b_onestep: numpy array with shape [N, ], updated vector of b_{k+1:T}\n",
    "\n",
    "        \"\"\"\n",
    "        # Acquire the row vector and transform it to diagonal matrix\n",
    "        O_matrix = self.compute_observation_matrix(observation)\n",
    "        b_onestep = None\n",
    "        #######################################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #######################################\n",
    "        return b_onestep\n",
    "        \n",
    "        \n",
    "    def forward_backward(self, observation_sequence):\n",
    "        \"\"\" forward-backward algorithm for smoothing\n",
    "            In this function, you will finalize the forward-backward algorithm based on your previous implementaions\n",
    "            of function “forward_onestep” and \"backward_onestep\".\n",
    "            \n",
    "            Remember to normalize the result smoothed probabilty to ensure the probability sum to be 1! \n",
    "            Note: We provide normalization function as a reference, you can also implement your own :)\n",
    "       \n",
    "            T stands for sequence lenghth and N stands for number of hidden states.\n",
    "\n",
    "        Args:\n",
    "            observation_sequence: observed sequence in a given period with length T\n",
    "            \n",
    "\n",
    "        Return: \n",
    "            smoothed_prob: numpy array with shape [T, N], state probability in this period after smoothing.\n",
    "\n",
    "        \"\"\"\n",
    "        forward_prob = {}\n",
    "        smoothed_prob = {}\n",
    "        backward_prob = {}\n",
    "        #######################################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #######################################\n",
    "        return dict_to_array(smoothed_prob)\n",
    "\n",
    "        \n",
    "    def predict(self, observation_sequence, k):\n",
    "        \"\"\" Predict state probability for future timestamp, remember to filter the given observation sequence at first.\n",
    "            \n",
    "            Remember to normalize the result forward probabilty to ensure the probability sum to be 1! \n",
    "            Note: We provide normalization function as a reference, you can also implement your own :)\n",
    "            \n",
    "            N stands for number of hidden states.\n",
    "\n",
    "        Args:\n",
    "            observation_sequence: observed sequence in a given period with length T\n",
    "            k: the number of steps of timestamp T\n",
    "            \n",
    "        Return: \n",
    "            p: numpy array with shape [N, ], vector of state probability after k steps of timestamp T in the future\n",
    "             \n",
    "        \"\"\"\n",
    "        #######################################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #######################################\n",
    "        return p\n",
    "        \n",
    "\n",
    "    def viterbi(self, observation_sequence):\n",
    "        \"\"\" Compute the most likely state trajectory given a observation sequence.\n",
    "            T stands for sequence lenghth.\n",
    "\n",
    "        Args:\n",
    "            observation_sequence: observed sequence in a given period with length T\n",
    "            \n",
    "        Return: \n",
    "            trajectory: numpy array with shape [T, ], trajectory of the most likely state in the given period.\n",
    "            Note that the output trajectory is in the form of the corresponding indices of the states. For example,\n",
    "            the output with numpy array [1, 7, 5] denotes given a sequence with lenghth T=3, the most likely state \n",
    "            trasnforms from state 1 to state 7 and finally to state 5.\n",
    "        \"\"\"\n",
    "        max_prob = {}\n",
    "        most_likely_state = {}\n",
    "        trajectory = {}\n",
    "        #######################################\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        #######################################\n",
    "        return dict_to_array(trajectory)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(logit, axis=0):\n",
    "        prob = logit / np.sum(logit, axis=axis)\n",
    "        return prob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Your Implementations\n",
    "\n",
    "Let's run your implemented functions with some dummy data.\n",
    "\n",
    "**Please DON'T change the pre-defined parameters below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined model parameters for HMM testing\n",
    "# Input transition matrix, NxN matrix in our scenario (N states)\n",
    "T = np.array([[0.2, 0.6],\n",
    "              [0.8, 0.4]])\n",
    "\n",
    "# Input mean of gaussian variable here, Nx2 matrix in our scenario,\n",
    "# Since each state has its own corresponding gaussian distribution (N states), and the dimension of the observation is H.\n",
    "# For each H-dimensional gaussian distribution, its corresponding mean (mu) vector shall has H dimension.\n",
    "# So we input 7xH matrix as *mus* in our scenario.\n",
    "mus = np.array([[0.8, 0.7], \n",
    "                [0.3, 0.2]])\n",
    "\n",
    "# Input mean of gaussian variable here, NxHxH matrix in our scenario,\n",
    "# Since each state has its own corresponding gaussian distribution (N states), and the dimension of the observation is H.\n",
    "# For each H-dimensional gaussian distribution, its corresponding covariance matrix (sigma) shall be HxH.\n",
    "# So we input NxHxH matrix as *sigmas* in our scenario.\n",
    "sigmas = np.zeros((2, 2, 2))\n",
    "sigmas[0] = np.eye(2)\n",
    "sigmas[1] = np.eye(2)\n",
    "\n",
    "# Input initialized state distribution here, a vector with N dimension. (N states)\n",
    "init_prob = np.array([0.3, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import test_hmm\n",
    "\n",
    "# Initialize your implemented HMM model!\n",
    "hmm = HMM(mus, sigmas, T, init_prob) \n",
    "\n",
    "# Test each implemenation module :)\n",
    "test_hmm('forward_backward', hmm)    \n",
    "test_hmm('prediction', hmm)    \n",
    "test_hmm('viterbi', hmm)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply HMM for COVID Severity Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, your final task is to use the use HMM model for COVID severity estimation as a guide for examination decision-makers. \n",
    "\n",
    "You may refer to this [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543670) to better understand the how we can leverage HMM to model the spread progress of COVID given some observation data such as daily and cumulative infections and daily deaths.\n",
    "\n",
    "In this task, we define the following components of HMM as follows:\n",
    "\n",
    "```\n",
    "Hidden State: Severity of the COVID, there are 7 discrete levels in total and the transition diagram is shown in below.\n",
    "Observation: A 7 * 2 matrix (mus) and a 7 * 2 * 2 matrix (sigmas)\n",
    "Transformation Model: A 7 * 7 matrix that depicts the internal relationship between each state.\n",
    "Sensor Model: A 2-dimensional gaussian distribution based on given state.\n",
    "```\n",
    "\n",
    "It can be a little bit tricky since in this scenario the sensor model is modeled as a continuous probability density distribution instead of a discrete matrix as discussed during lectures. While don't be panic since we have  provided you a helper function to extract the diagonal observation matrix (O_matrix), and then the algorithm for filtering, smoothing and viterbi will be just the same as the discrete case we dealt with during class ;) \n",
    "\n",
    "We will provide pre-estimated HMM parameters for you such as transformation matrix and preprocessed data, let's now take a look on how we use HMM to model COVID :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitional Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the transitional matrix as the following figure shows:\n",
    "![title](img/transitional_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# T is a 7 * 7 matrix, T(ij) means the probability from state i to state j\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the observational matrix as the following figure shows:\n",
    "<img src='img/observational_matrix.png'  width='35%'  height='35%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# mus is a 7 * 2 matrix, which indicates the input mean of gaussian variable\n",
    "# sigmas is a 7 * 2 * 2 matrix, which indicates the input covariance of gaussian variable. Each state has a 2 * 2 covariance matrix\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized State Distribution (Nothing to do here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_prob is a 7-dimensional vector\n",
    "init_prob = np.array([0.414, 0, 0.401, 0.137, 0, 0, 0.047])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obsevation Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we take into account 21 months in total, the sequence is a 21 * 2 matrix which contains both confirmed cases and death cases.\n",
    "\n",
    "**The sequence can be found in sequence.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# obsevation sequence is a 21 * 2 matrix containing both confirmed cases and death cases, here, we define 2 sequences, one for Munich,\n",
    "# one for LK_Munich\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (Nothing to change here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Forward-backward algorithm\n",
    "hmm = HMM(mus, sigmas, T, init_prob)\n",
    "smoothed_prob_Munich = hmm.forward_backward(obs_seq_Munich)\n",
    "smoothed_prob_LK_Munich = hmm.forward_backward(obs_seq_LK_Munich)\n",
    "print('smoothed_prob_Munich: \\n', smoothed_prob_Munich, '\\n')\n",
    "print('smoothed_prob_LK_Munich: \\n', smoothed_prob_LK_Munich, '\\n')\n",
    "\n",
    "# Test Prediction\n",
    "predicted_prob_Munich = hmm.predict(obs_seq_Munich, 10)\n",
    "predicted_prob_LK_Munich = hmm.predict(obs_seq_LK_Munich, 10)\n",
    "print('prediction_Munich: \\n', predicted_prob_Munich, '\\n')\n",
    "print('prediction_LK_Munich: \\n', predicted_prob_LK_Munich, '\\n')\n",
    "\n",
    "\n",
    "# Test viterbi algorithm\n",
    "trajectory_Munich = hmm.viterbi(obs_seq_Munich)\n",
    "trajectory_LK_Munich = hmm.viterbi(obs_seq_LK_Munich)\n",
    "print('trajectory_Munich: \\n',trajectory_Munich, '\\n')\n",
    "print('trajectory_LK_Munich: \\n',trajectory_LK_Munich, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nothing to change here**\n",
    "\n",
    "Now that we have the trajectory, we can visualize the result using matplotlib or dataframe(pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the result in plt\n",
    "\n",
    "months = ['Apr 2020', 'May 2020', 'Jun 2020', 'Jul 2020', 'Aug 2020', 'Sep 2020', 'Oct 2020','Nov 2020', \\\n",
    "          'Dec 2020', 'Jan 2021', 'Feb 2021', 'Mar 2021', 'Apr 2021', 'May 2021', 'Jun 2021','Jul 2021', \\\n",
    "          'Aug 2021', 'Sep 2021', 'Oct 2021', 'Nov 2021', 'Dec 2021']\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#Munich\n",
    "plt.subplot(2, 1, 1)\n",
    "fig_Munich = plt.step(months, trajectory_Munich, color=\"#8dd3c7\", where=\"pre\", lw=2)\n",
    "plt.ylim(1, 7)\n",
    "plt.title('Severity of COVID-19 in Munich')\n",
    "\n",
    "#LK_Munich\n",
    "plt.subplot(2, 1, 2)\n",
    "fig_LK_Munich = plt.step(months, trajectory_LK_Munich, color=\"#8dd3c7\", where=\"pre\", lw=2)\n",
    "plt.ylim(1, 7)\n",
    "plt.title('Severity of COVID-19 in LK Munich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the result in DataFrame\n",
    "data = [months, list(trajectory_Munich), list(trajectory_LK_Munich)]\n",
    "df = pd.DataFrame(np.transpose(data), columns=['Months', 'Munich','LK_Munich'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
